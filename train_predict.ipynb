{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-22T18:26:36.331587Z","iopub.status.busy":"2023-01-22T18:26:36.331178Z","iopub.status.idle":"2023-01-22T18:26:36.339036Z","shell.execute_reply":"2023-01-22T18:26:36.337918Z","shell.execute_reply.started":"2023-01-22T18:26:36.33154Z"},"trusted":true},"outputs":[],"source":["VER = 1\n","import pandas as pd, numpy as np\n","import pickle, glob, gc\n","\n","from collections import Counter\n","import itertools\n","import os\n","from tqdm import tqdm\n","import time\n","\n","# multiprocessing \n","import psutil\n","N_CORES = min(psutil.cpu_count(),32)     # Available CPU cores\n","print(f\"N Cores : {N_CORES}\")\n","from multiprocessing import Pool\n","from matplotlib import pyplot as plt\n","\n","import lightgbm as lgb\n","from lightgbm.sklearn import LGBMRanker\n","from sklearn.model_selection import GroupKFold\n","\n","REMARKS = \"过滤所有无交互\"\n","KFOLDS = 3"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def filter_out_neg_sessions(train_set,target,frac=0.9):\n","    # 过滤无target行为的用户\n","    session_target_sum = train_set.groupby('session')[target].sum().to_frame()\n","    filter_out_session = session_target_sum[session_target_sum[target]==0].sample(frac=frac) # 保留一部分用户\n","    train_set = train_set[~train_set.session.isin(filter_out_session.index)]\n","    return train_set\n","\n","def neg_sample(train_set,target,neg_sample_ratio):\n","    # 对负例进行采样，正：负=1：neg_sample_ratio。\n","    positives = train_set[train_set[target]==1]\n","    negatives = train_set[train_set[target]==0].sample(n=positives.shape[0]*neg_sample_ratio)\n","    train_set = pd.concat([positives,negatives],axis=0,ignore_index=True).sample(frac=1).sort_values(['session'])\n","    train_set.groupby('session').aid.count().hist()\n","    plt.show()\n","    return train_set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:04:35.159953Z","iopub.status.busy":"2023-01-22T18:04:35.159531Z","iopub.status.idle":"2023-01-22T18:04:35.166132Z","shell.execute_reply":"2023-01-22T18:04:35.165074Z","shell.execute_reply.started":"2023-01-22T18:04:35.15992Z"},"trusted":true},"outputs":[],"source":["params = {\n","    'device':'gpu',\n","    'learning_rate': 0.1,\n","    'max_depth': 10,\n","    'num_leaves':256,\n","    'early_stopping_round':10,\n","    'objective':\"lambdarank\",\n","    'metric':\"ndcg\",\n","    'colsample_bytree': 0.9,\n","    'subsample':0.9,\n","    'boosting_type':\"gbdt\",\n","    'n_estimators':20,\n","    'importance_type':'gain'\n","}"]},{"cell_type":"markdown","metadata":{},"source":["cart"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:11:56.618989Z","iopub.status.busy":"2023-01-22T18:11:56.618342Z","iopub.status.idle":"2023-01-22T18:19:41.472064Z","shell.execute_reply":"2023-01-22T18:19:41.471121Z","shell.execute_reply.started":"2023-01-22T18:11:56.618949Z"},"trusted":true},"outputs":[],"source":["%%time\n","# load数据\n","TARGET = 'carts' # carts/orders\n","print(f\"TARGET = {TARGET}\")\n","\n","train_set = pd.read_parquet(f\"../feature/less_train_with_feature.pqt\")\n","train_set = filter_out_neg_sessions(train_set,TARGET,frac=1)\n","display(train_set.head(10))\n","\n","print(f\"Session avg aid len = {np.mean(train_set.groupby('session').aid.nunique())}\")\n","print(f\"Session avg {TARGET} num = {train_set.groupby('session')[TARGET].sum().mean()}\")\n","print(f\"Train with {train_set.session.nunique()} users\")\n","\n","FEATURES = train_set.columns[5:]\n","print(f\"FEATURES = {FEATURES}\")\n","# 开始训练\n","skf = GroupKFold(n_splits=KFOLDS)\n","for fold,(train_idx, valid_idx) in tqdm(enumerate(skf.split(train_set, train_set[TARGET], groups=train_set['session']))):\n","\n","    X_train = train_set.iloc[train_idx][FEATURES]\n","    y_train = train_set.iloc[train_idx][TARGET]\n","    X_valid = train_set.iloc[valid_idx][FEATURES]\n","    y_valid = train_set.iloc[valid_idx][TARGET]\n","    group_train = train_set.iloc[train_idx].groupby('session')['session'].count()\n","    group_valid = train_set.iloc[valid_idx].groupby('session')['session'].count()\n","    print(train_idx.shape,X_train.shape,y_train.shape)\n","    ranker = LGBMRanker(\n","        **params\n","    )\n","    ranker = ranker.fit(\n","        X_train,\n","        y_train,\n","        group=group_train,\n","        eval_set=[(X_train,y_train),(X_valid, y_valid)],\n","        eval_group=[group_train,group_valid],\n","        eval_at=(1,5,10,20)\n","    )\n","    lgb.plot_metric(ranker)\n","    lgb.plot_importance(ranker,max_num_features=20)\n","    plt.show()\n","    ranker.booster_.save_model(f'LGBM_fold{fold}_{TARGET}_{REMARKS}.txt')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["order"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:04:35.521956Z","iopub.status.busy":"2023-01-22T18:04:35.521215Z","iopub.status.idle":"2023-01-22T18:11:56.61629Z","shell.execute_reply":"2023-01-22T18:11:56.615094Z","shell.execute_reply.started":"2023-01-22T18:04:35.52191Z"},"trusted":true},"outputs":[],"source":["%%time\n","# train lgb model\n","import lightgbm as lgb\n","from lightgbm.sklearn import LGBMRanker\n","from sklearn.model_selection import GroupKFold\n","\n","# load数据\n","TARGET = 'orders' # carts/orders\n","print(f\"TARGET = {TARGET}\")\n","\n","train_set = pd.read_parquet(f\"../feature/less_train_with_feature.pqt\")\n","train_set = filter_out_neg_sessions(train_set,TARGET,frac=1)\n","display(train_set.head(10))\n","\n","print(f\"Session avg aid len = {np.mean(train_set.groupby('session').aid.nunique())}\")\n","print(f\"Session avg {TARGET} num = {train_set.groupby('session')[TARGET].sum().mean()}\")\n","print(f\"Train with {train_set.session.nunique()} users\")\n","\n","FEATURES = train_set.columns[5:]\n","print(f\"FEATURES = {FEATURES}\")\n","\n","# 训练\n","skf = GroupKFold(n_splits=KFOLDS)\n","for fold,(train_idx, valid_idx) in tqdm(enumerate(skf.split(train_set, train_set[TARGET], groups=train_set['session']))):\n","\n","    X_train = train_set.iloc[train_idx][FEATURES]\n","    y_train = train_set.iloc[train_idx][TARGET]\n","    X_valid = train_set.iloc[valid_idx][FEATURES]\n","    y_valid = train_set.iloc[valid_idx][TARGET]\n","    group_train = train_set.iloc[train_idx].groupby('session')['session'].count()\n","    group_valid = train_set.iloc[valid_idx].groupby('session')['session'].count()\n","    print(train_idx.shape,X_train.shape,y_train.shape)\n","\n","    ranker = LGBMRanker(\n","        **params\n","    )\n","    ranker = ranker.fit(\n","        X_train,\n","        y_train,\n","        group=group_train,\n","        eval_set=[(X_train,y_train),(X_valid, y_valid)],\n","        eval_group=[group_train,group_valid],\n","        eval_at=(1,5,10,20)\n","    )\n","    lgb.plot_metric(ranker)\n","    lgb.plot_importance(ranker,max_num_features=20)\n","    plt.show()\n","    ranker.booster_.save_model(f'LGBM_fold{fold}_{TARGET}_{REMARKS}.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:20:32.366762Z","iopub.status.busy":"2023-01-22T18:20:32.366389Z","iopub.status.idle":"2023-01-22T18:20:32.509817Z","shell.execute_reply":"2023-01-22T18:20:32.508546Z","shell.execute_reply.started":"2023-01-22T18:20:32.366731Z"},"trusted":true},"outputs":[],"source":["del train_set\n","_ = gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Metric"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# eval lgb model\n","import lightgbm as lgb\n","from lightgbm.sklearn import LGBMRanker\n","\n","def df_parallelize_run(func, t_split):\n","    num_cores = np.min([N_CORES, len(t_split)])\n","    pool = Pool(num_cores)\n","    df = pool.map(func, t_split)\n","    pool.close()\n","    pool.join()\n","    \n","    return df\n","\n","def predict_save(test_set,features,target,save_file_prefix='test'):\n","    print(f\"Predicting using features {features}\")\n","    preds = np.zeros(len(test_set))\n","    for fold in tqdm(range(KFOLDS)):\n","        model = lgb.Booster(model_file=f'LGBM_fold{fold}_{target}_{REMARKS}.txt')\n","        preds += model.predict(test_set[features])/KFOLDS\n","    predictions = test_set[['session','aid']].copy()\n","    predictions['pred'] = preds\n","\n","    predictions = predictions.sort_values(['session','pred'], ascending=[True,False]).reset_index(drop=True)\n","    predictions['n'] = predictions.groupby('session').aid.cumcount().astype('int8')\n","    predictions = predictions.loc[predictions.n<20]\n","    predictions.to_csv(f\"{save_file_prefix}_intermediate_{target}_predictions.csv\",index=False)\n","    sub = predictions.groupby('session').aid.apply(list)\n","    sub = sub.to_frame().reset_index()\n","    sub.aid = sub.aid.apply(lambda x: \" \".join(map(str,x)))\n","    sub.columns = ['session_type','labels']\n","    sub.session_type = sub.session_type.astype('str')+ f'_{target}'\n","    sub.to_csv(f\"{save_file_prefix}_{target}_predictions.csv\",index=False)\n","    display(sub.head(10))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["benchmark = {\"clicks\":0.5255597442145808, \"carts\":0.4093328152483512, \"orders\":0.6487936598117477, \"all\":.5646320148830121}\n","weights = {'clicks': 0.10, 'carts': 0.30, 'orders': 0.60}\n","\n","valid_labels = pd.read_parquet('../input/otto-validation/test_labels.parquet')\n","\n","def df_parallelize_run(func, t_split):\n","    num_cores = np.min([N_CORES, len(t_split)])\n","    pool = Pool(num_cores)\n","    df = pool.map(func, t_split)\n","    pool.close()\n","    pool.join()\n","    \n","    return df\n","\n","def hits(b):\n","    # b[0] : session id\n","    # b[1] : ground truth\n","    # b[2] : aids prediction \n","    return b[0], len(set(b[1]).intersection(set(b[2]))), np.clip(len(b[1]), 0, 20)\n","\n","def otto_metric_piece(values, typ, verbose=True):\n","    '''\n","    pred==> index: session|aid_list\n","    '''\n","    c1 = pd.DataFrame(values, columns=[\"labels\"]).reset_index().rename({\"index\":\"session\"}, axis=1)\n","    a = valid_labels[valid_labels['type']==typ].merge(c1, how='left', on=['session'])\n","\n","    b=[[a0, a1, a2] for a0, a1, a2 in zip(a[\"session\"], a[\"ground_truth\"], a[\"labels\"])]\n","    try:\n","        c = df_parallelize_run(hits, b)\n","    except Exception as e:\n","        print(f'Error {e}, labels = {a.labels}')\n","        return -1\n","    c = np.array(c)\n","    \n","    recall = c[:,1].sum() / c[:,2].sum()\n","    \n","    print('{} recall = {:.5f} (vs {:.5f} in benchmark)'.format(typ ,recall, benchmark[typ]))\n","    \n","    return recall\n","\n","\n","def otto_metric(clicks, carts, orders, verbose = True):\n","    \n","    score = 0\n","    score += weights[\"clicks\"] * otto_metric_piece(clicks, \"clicks\", verbose = verbose)\n","    score += weights[\"carts\"] * otto_metric_piece(carts, \"carts\", verbose = verbose)\n","    score += weights[\"orders\"] * otto_metric_piece(orders, \"orders\", verbose = verbose)\n","    \n","    if verbose:\n","        print('=============')\n","        print('Overall Recall = {:.5f} (vs {:.5f} in benchmark)'.format(score, benchmark[\"all\"]))\n","        print('=============')\n","    \n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %%time\n","# train_set = pd.read_parquet(f\"../feature/less_train_with_feature.pqt\")\n","# FEATURES = train_set.columns[5:]\n","# print('Predicting carts...')\n","# predict_save(train_set,FEATURES,'carts','val')\n","# print('Predicting orders...')\n","# predict_save(train_set,FEATURES,'orders','val')\n","\n","# print('Predicting clicks')\n","# clicks_candidates = pd.read_parquet(\"../recall/val/clicks_candidates.pqt\")\n","# sub = clicks_candidates.reset_index().rename(columns={'index':'session_type','aid_list':'labels'})\n","# sub.labels = sub.labels.apply(lambda x: \" \".join(map(str,x[:20])))\n","# sub.session_type = sub.session_type.astype('str')+ f'_clicks'\n","# sub.to_csv(\"./val_clicks_predictions.csv\",index=False)\n","# display(sub.head(10))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 计算recall rate和总分数\n","# val_clicks = pd.read_csv(\"./val_clicks_predictions.csv\")\n","# val_clicks.columns = ['session','labels']\n","# val_clicks.session = val_clicks.session.apply(lambda x:int(x.split('_')[0]))\n","# val_clicks.labels = val_clicks.labels.apply(lambda x:list(map(int,x.split(' '))))\n","# val_clicks = val_clicks.set_index(['session'])\n","# val_carts = pd.read_csv(\"./val_carts_predictions.csv\")\n","# val_carts.columns = ['session','labels']\n","# val_carts.session = val_carts.session.apply(lambda x:int(x.split('_')[0]))\n","# val_carts.labels = val_carts.labels.apply(lambda x:list(map(int,x.split(' '))))\n","# val_carts = val_carts.set_index(['session'])\n","# val_orders = pd.read_csv(\"./val_orders_predictions.csv\")\n","# val_orders.columns = ['session','labels']\n","# val_orders.session = val_orders.session.apply(lambda x:int(x.split('_')[0]))\n","# val_orders.labels = val_orders.labels.apply(lambda x:list(map(int,x.split(' '))))\n","# val_orders = val_orders.set_index(['session'])\n","# _ = otto_metric(val_clicks, val_carts, val_orders)"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:25:10.377021Z","iopub.status.busy":"2023-01-22T18:25:10.376453Z","iopub.status.idle":"2023-01-22T18:25:10.40493Z","shell.execute_reply":"2023-01-22T18:25:10.403771Z","shell.execute_reply.started":"2023-01-22T18:25:10.376906Z"},"trusted":true},"outputs":[],"source":["VER = 1\n","import pandas as pd, numpy as np\n","import pickle, glob, gc\n","\n","from collections import Counter\n","import itertools\n","import os\n","from tqdm import tqdm\n","import time\n","\n","# multiprocessing \n","import psutil\n","N_CORES = psutil.cpu_count()     # Available CPU cores\n","print(f\"N Cores : {N_CORES}\")\n","from multiprocessing import Pool"]},{"cell_type":"markdown","metadata":{},"source":["使用同一批候选，但是模型分别用两种order和cart两种模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:25:11.490226Z","iopub.status.busy":"2023-01-22T18:25:11.489209Z","iopub.status.idle":"2023-01-22T18:25:24.542984Z","shell.execute_reply":"2023-01-22T18:25:24.54175Z","shell.execute_reply.started":"2023-01-22T18:25:11.490181Z"},"trusted":true},"outputs":[],"source":["test_set = pd.read_parquet(\"../feature/less_test_with_feature.pqt\")\n","assert test_set.session.nunique()==1671803, \"User cnt is wrong, please chekc your feature generation part!\"\n","test_set.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:25:28.005342Z","iopub.status.busy":"2023-01-22T18:25:28.004621Z","iopub.status.idle":"2023-01-22T18:25:57.94571Z","shell.execute_reply":"2023-01-22T18:25:57.944645Z","shell.execute_reply.started":"2023-01-22T18:25:28.005301Z"},"trusted":true},"outputs":[],"source":["%%time\n","FEATURES = test_set.columns[2:]\n","print('Predicting carts...')\n","predict_save(test_set,FEATURES,'carts','test')\n","print('Predicting orders...')\n","predict_save(test_set,FEATURES,'orders','test')\n","\n","clicks_candidates = pd.read_parquet(\"../recall/test/clicks_candidates.pqt\")\n","sub = clicks_candidates.reset_index().rename(columns={'index':'session_type','aid_list':'labels'})\n","sub.labels = sub.labels.apply(lambda x: \" \".join(map(str,x[:20])))\n","sub.session_type = sub.session_type.astype('str')+ f'_clicks'\n","sub.to_csv(\"test_clicks_predictions.csv\",index=False)\n","display(sub.head(10))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 提交"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","import pandas as pd\n","clicks = pd.read_csv(\"test_clicks_predictions.csv\")\n","carts = pd.read_csv(\"test_carts_predictions.csv\")\n","orders = pd.read_csv(\"test_orders_predictions.csv\")\n","sub = pd.concat([clicks,carts,orders])\n","sub.to_csv(\"submission.csv\",index=False)\n","sub.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T18:31:39.519975Z","iopub.status.busy":"2023-01-22T18:31:39.519544Z","iopub.status.idle":"2023-01-22T18:32:19.877455Z","shell.execute_reply":"2023-01-22T18:32:19.876205Z","shell.execute_reply.started":"2023-01-22T18:31:39.519935Z"},"trusted":true},"outputs":[],"source":["# !kaggle competitions submit -c otto-recommender-system -f submission.csv -m \"more feature\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"kaggle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"a3218bb28529b36eec24a9024c4e375ca4dd97d153ce39508d999fa46c0f46b5"}}},"nbformat":4,"nbformat_minor":4}
